# Basic Tokenizer
Python based tokenizer made to identify lexical tokens as part of learning about programming languages. Currently only written for compatability with .jack files.
Creates a .xml text file named tokenizer continaing the results of the tokenization upon running in folder the program is in.

To be updated small error regarding detection of spaces inside text strings. 
